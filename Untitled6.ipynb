{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206c48e9-ba22-4e0a-b28e-f880b2533310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#code for 1.23GCG\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def preprocess_image(image_path, target_size=(416, 416)):\n",
    "    \"\"\"Preprocesses a single image.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "def augment_image(image, bounding_boxes, target_size=(416,416)):\n",
    "    \"\"\"Applies data augmentation to an image and its bounding boxes.\"\"\"\n",
    "    rows, cols, _ = image.shape\n",
    "\n",
    "    # Random horizontal flip\n",
    "    if random.random() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        bounding_boxes[:, 1] = 1 - bounding_boxes[:, 1] #adjust x center\n",
    "\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows))\n",
    "    #adjust bounding boxes for rotation.\n",
    "    cos = np.cos(np.radians(angle))\n",
    "    sin = np.sin(np.radians(angle))\n",
    "    for box in bounding_boxes:\n",
    "        x_center = box[1] * cols\n",
    "        y_center = box[2] * rows\n",
    "        new_x = (x_center * cos) - (y_center * sin)\n",
    "        new_y = (x_center * sin) + (y_center * cos)\n",
    "        box[1] = new_x / cols\n",
    "        box[2] = new_y / rows\n",
    "\n",
    "    #Random brightness and contrast.\n",
    "    alpha = random.uniform(0.7,1.3)\n",
    "    beta = random.uniform(-20,20)\n",
    "    image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "    return image, bounding_boxes\n",
    "\n",
    "def load_and_preprocess_dataset(image_paths, label_paths, target_size=(416,416), augment = False):\n",
    "    \"\"\"Loads and preprocesses the entire dataset.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_path, label_path in zip(image_paths, label_paths):\n",
    "        img = preprocess_image(image_path, target_size)\n",
    "        bounding_boxes = load_bounding_boxes(label_path)\n",
    "        if augment == True:\n",
    "          img, bounding_boxes = augment_image(img, bounding_boxes, target_size)\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(bounding_boxes)\n",
    "    return np.array(images), labels\n",
    "\n",
    "def load_bounding_boxes(label_path):\n",
    "    \"\"\"Loads bounding box annotations from a YOLOv5 label file.\"\"\"\n",
    "    bounding_boxes = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            bounding_boxes.append([class_id, x_center, y_center, width, height])\n",
    "    return np.array(bounding_boxes)\n",
    "\n",
    "#Example of usage.\n",
    "#image_paths = [\"path/to/image1.jpg\", \"path/to/image2.jpg\"]\n",
    "#label_paths = [\"path/to/label1.txt\", \"path/to/label2.txt\"]\n",
    "#images, labels = load_and_preprocess_dataset(image_paths, label_paths, augment = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9717c-c8fd-406f-a627-a1e4bb619d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
